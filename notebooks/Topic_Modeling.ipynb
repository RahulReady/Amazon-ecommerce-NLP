{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599826543718",
   "display_name": "Python 3.8.0 64-bit ('amazon-nlp-env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling for Customer Reviews\n",
    "Once we classify negative reviews, the next step is to understand why the reviews are negative. Ideally, we want to find patterns that are common in negative reviews that would help product owners pinpoint the problem areas for products.\n",
    "\n",
    "## Background:\n",
    "  ### What is topic modeling?\n",
    "  \"A topic model is a type of statistical model for discovering abstract 'topics' that occur in a collection of documents.\" [Wikipedia]\n",
    "  ![lda](./../images/lda.png)\n",
    "  ![lda](./../images/lda1.png)\n",
    "  ![lda](./../images/lda2.png)\n",
    "  ![lda](./../images/lda3.png)\n",
    "\n",
    " ### What is topic modeling used for?\n",
    " * It can be used to identify topics of a news article. Ex - Sports, politics, economy etc\n",
    " * Tagging customer support issues. Ex - Billing issue, shipping issue, account issue etc.\n",
    " * Providing 'similar' articles to read on magazine websites. \n",
    "\n",
    "### References:\n",
    "Parts of the code were adapted and modified from these references: <br>\n",
    "https://www.youtube.com/watch?v=NYkbqzTlW3w&ab_channel=AliceZhao <br>\n",
    "https://towardsdatascience.com/topic-modeling-with-nlp-on-amazon-reviews-an-application-of-latent-dirichlet-allocation-lda-ae42a4c8b369\n",
    "<br><br>\n",
    "Slides: <br>\n",
    "https://www.youtube.com/watch?v=BuMu-bdoVrU&ab_channel=PyTexas<br>\n",
    "https://www.youtube.com/watch?v=NYkbqzTlW3w&ab_channel=AliceZhao <br> <br>\n",
    "Theory <br>\n",
    "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to /Users/rahul/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/rahul/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
    }
   ],
   "source": [
    "# Mac issue fix\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# General Packages \n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# NLP preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "import string\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# LDA modules\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing and exploring the data\n",
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Assumes you have the data already from running the relevant code in the 'NLP_for_Customer_Reviews.ipynb'\n",
    "\n",
    "col_names = [\"label\", \"title\", \"review\"]\n",
    "\n",
    "train_df = pd.read_csv('./amazon_review_polarity_csv/train.csv', names=col_names)\n",
    "df = pd.read_csv('./amazon_review_polarity_csv/test.csv', names = col_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   label                                              title  \\\n0      2                                           Great CD   \n1      2  One of the best game music soundtracks - for a...   \n2      1                   Batteries died within a year ...   \n3      2              works fine, but Maha Energy is better   \n4      2                       Great for the non-audiophile   \n\n                                              review  \n0  My lovely Pat has one of the GREAT voices of h...  \n1  Despite the fact that I have only played a sma...  \n2  I bought this charger in Jul 2003 and it worke...  \n3  Check out Maha Energy's website. Their Powerex...  \n4  Reviewed quite a bit of the combo players and ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>title</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Great CD</td>\n      <td>My lovely Pat has one of the GREAT voices of h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>One of the best game music soundtracks - for a...</td>\n      <td>Despite the fact that I have only played a sma...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Batteries died within a year ...</td>\n      <td>I bought this charger in Jul 2003 and it worke...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>works fine, but Maha Energy is better</td>\n      <td>Check out Maha Energy's website. Their Powerex...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Great for the non-audiophile</td>\n      <td>Reviewed quite a bit of the combo players and ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# For more in depth exploration, see 'NLP_for_Customer_Reviews.ipynb'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 400000 entries, 0 to 399999\nData columns (total 3 columns):\n #   Column  Non-Null Count   Dtype \n---  ------  --------------   ----- \n 0   label   400000 non-null  int64 \n 1   title   399990 non-null  object\n 2   review  400000 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 9.2+ MB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "One of the best game music soundtracks - for a game I didn't really play\n\nDespite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n"
    }
   ],
   "source": [
    "# Sample title and review\n",
    "print(df.iloc[1, 1] + '\\n\\n' + df.iloc[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation\n",
    "### Subsetting relevant negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   label                                  title  \\\n2      1       Batteries died within a year ...   \n5      1  DVD Player crapped out after one year   \n6      1                         Incorrect Disc   \n7      1               DVD menu select problems   \n9      1                Not an \"ultimate guide\"   \n\n                                              review  \n2  I bought this charger in Jul 2003 and it worke...  \n5  I also began having the incorrect disc problem...  \n6  I love the style of this, but after a couple y...  \n7  I cannot scroll through a DVD menu that is set...  \n9  Firstly,I enjoyed the format and tone of the b...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>title</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Batteries died within a year ...</td>\n      <td>I bought this charger in Jul 2003 and it worke...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>DVD Player crapped out after one year</td>\n      <td>I also began having the incorrect disc problem...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>Incorrect Disc</td>\n      <td>I love the style of this, but after a couple y...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>DVD menu select problems</td>\n      <td>I cannot scroll through a DVD menu that is set...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>Not an \"ultimate guide\"</td>\n      <td>Firstly,I enjoyed the format and tone of the b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# For the sake of saving compute resources, we will work with 10,000 negative reviews. \n",
    "# Subsetting 10,000 negative reviews for analysis\n",
    "df1 = df[df['label'] == 1]\n",
    "df1 = df1.iloc[0:10001, :]\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   label                                               Text\n2      1  Batteries died within a year ... I bought this...\n5      1  DVD Player crapped out after one year I also b...\n6      1  Incorrect Disc I love the style of this, but a...\n7      1  DVD menu select problems I cannot scroll throu...\n9      1  Not an \"ultimate guide\" Firstly,I enjoyed the ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Batteries died within a year ... I bought this...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>DVD Player crapped out after one year I also b...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>Incorrect Disc I love the style of this, but a...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>DVD menu select problems I cannot scroll throu...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>Not an \"ultimate guide\" Firstly,I enjoyed the ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# Combining the tile and reviews into a text column (the idea being the title can help with identifying topics)\n",
    "df1['Text'] = df1['title'] + ' ' + df1['review']\n",
    "df1 = df1.drop(['title', 'review'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Dropping 1 null value row\n",
    "df1 = df1.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = CountVectorizer(stop_words = stop_words)\n",
    "cv_data = cv.fit_transform(df1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10000, 33319)"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "cv_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at our document - term matrix\n",
    "data = pd.DataFrame(cv_data.toarray(), columns = cv.get_feature_names())\n",
    "data.index = df1['Text'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       00  000  00000  007  00and2  01  010  02  029  03  ...  zzzzzzzzzzzz  \\\n2       0    0      0    0       0   0    0   0    0   0  ...             0   \n5       0    0      0    0       0   0    0   0    0   0  ...             0   \n6       0    0      0    0       0   0    0   0    0   0  ...             0   \n7       0    0      0    0       0   0    0   0    0   0  ...             0   \n9       0    0      0    0       0   0    0   0    0   0  ...             0   \n...    ..  ...    ...  ...     ...  ..  ...  ..  ...  ..  ...           ...   \n20446   0    0      0    0       0   0    0   0    0   0  ...             0   \n20447   0    0      0    0       0   0    0   0    0   0  ...             0   \n20448   0    0      0    0       0   0    0   0    0   0  ...             0   \n20449   0    0      0    0       0   0    0   0    0   0  ...             0   \n20451   0    0      0    0       0   0    0   0    0   0  ...             0   \n\n       zzzzzzzzzzzzz  zzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzz  \\\n2                  0                0                 0                  0   \n5                  0                0                 0                  0   \n6                  0                0                 0                  0   \n7                  0                0                 0                  0   \n9                  0                0                 0                  0   \n...              ...              ...               ...                ...   \n20446              0                0                 0                  0   \n20447              0                0                 0                  0   \n20448              0                0                 0                  0   \n20449              0                0                 0                  0   \n20451              0                0                 0                  0   \n\n       zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzzzzzzzzz  \\\n2                       0                       0                          0   \n5                       0                       0                          0   \n6                       0                       0                          0   \n7                       0                       0                          0   \n9                       0                       0                          0   \n...                   ...                     ...                        ...   \n20446                   0                       0                          0   \n20447                   0                       0                          0   \n20448                   0                       0                          0   \n20449                   0                       0                          0   \n20451                   0                       0                          0   \n\n       ésta  único  \n2         0      0  \n5         0      0  \n6         0      0  \n7         0      0  \n9         0      0  \n...     ...    ...  \n20446     0      0  \n20447     0      0  \n20448     0      0  \n20449     0      0  \n20451     0      0  \n\n[10000 rows x 33319 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>00000</th>\n      <th>007</th>\n      <th>00and2</th>\n      <th>01</th>\n      <th>010</th>\n      <th>02</th>\n      <th>029</th>\n      <th>03</th>\n      <th>...</th>\n      <th>zzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzzzzzzzzz</th>\n      <th>ésta</th>\n      <th>único</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20446</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20447</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20448</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20449</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20451</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 33319 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        2      5      6      7      9      11     12     14     15     20     \\\n00          0      0      0      0      0      0      0      0      0      0   \n000         0      0      0      0      0      0      0      0      0      0   \n00000       0      0      0      0      0      0      0      0      0      0   \n007         0      0      0      0      0      0      0      0      0      0   \n00and2      0      0      0      0      0      0      0      0      0      0   \n\n        ...  20439  20440  20441  20442  20444  20446  20447  20448  20449  \\\n00      ...      0      0      0      0      0      0      0      0      0   \n000     ...      0      0      0      0      0      0      0      0      0   \n00000   ...      0      0      0      0      0      0      0      0      0   \n007     ...      0      0      0      0      0      0      0      0      0   \n00and2  ...      0      0      0      0      0      0      0      0      0   \n\n        20451  \n00          0  \n000         0  \n00000       0  \n007         0  \n00and2      0  \n\n[5 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>9</th>\n      <th>11</th>\n      <th>12</th>\n      <th>14</th>\n      <th>15</th>\n      <th>20</th>\n      <th>...</th>\n      <th>20439</th>\n      <th>20440</th>\n      <th>20441</th>\n      <th>20442</th>\n      <th>20444</th>\n      <th>20446</th>\n      <th>20447</th>\n      <th>20448</th>\n      <th>20449</th>\n      <th>20451</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>007</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00and2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# Required inputs: term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the term document matrix in a gensim format\n",
    "# df -> sparse mtx -> gensim corpus\n",
    "sparse = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires a dictionary of all the terms and their locations in the term-document matrix\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{3055: 'batteries',\n 8441: 'died',\n 33082: 'year',\n 4023: 'bought',\n 5304: 'charger'}"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# Sample of the id2word\n",
    "dict(list(id2word.items())[0: 5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analysis and iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.025*\"book\" + 0.007*\"read\" + 0.006*\"product\" + 0.005*\"don\" + 0.005*\"good\" + 0.005*\"work\" + 0.005*\"buy\" + 0.005*\"use\" + 0.004*\"money\" + 0.004*\"bought\"'),\n (1,\n  '0.016*\"movie\" + 0.008*\"good\" + 0.006*\"don\" + 0.006*\"really\" + 0.006*\"film\" + 0.006*\"bad\" + 0.005*\"story\" + 0.005*\"cd\" + 0.005*\"dvd\" + 0.005*\"album\"')]"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# We currently have the corpus(term-document matrix) and id2word (dictionary of location: term),\n",
    "# 2 parameters need to be specified: # of topics and number of passes \n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.031*\"book\" + 0.018*\"movie\" + 0.011*\"read\" + 0.007*\"good\" + 0.006*\"film\" + 0.006*\"story\" + 0.006*\"don\" + 0.005*\"really\" + 0.005*\"bad\" + 0.004*\"books\"'),\n (1,\n  '0.008*\"product\" + 0.007*\"dvd\" + 0.007*\"buy\" + 0.006*\"bought\" + 0.006*\"work\" + 0.006*\"use\" + 0.006*\"don\" + 0.006*\"money\" + 0.005*\"quality\" + 0.005*\"good\"'),\n (2,\n  '0.014*\"cd\" + 0.013*\"album\" + 0.011*\"music\" + 0.008*\"good\" + 0.008*\"songs\" + 0.006*\"don\" + 0.005*\"really\" + 0.005*\"sound\" + 0.005*\"bad\" + 0.004*\"song\"')]"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.009*\"product\" + 0.007*\"buy\" + 0.007*\"bought\" + 0.007*\"work\" + 0.006*\"use\" + 0.006*\"don\" + 0.005*\"quality\" + 0.005*\"money\" + 0.005*\"good\" + 0.004*\"amazon\"'),\n (1,\n  '0.013*\"book\" + 0.008*\"album\" + 0.008*\"good\" + 0.007*\"cd\" + 0.007*\"don\" + 0.007*\"read\" + 0.007*\"really\" + 0.006*\"music\" + 0.006*\"story\" + 0.005*\"boring\"'),\n (2,\n  '0.042*\"movie\" + 0.015*\"film\" + 0.009*\"bad\" + 0.009*\"good\" + 0.009*\"dvd\" + 0.007*\"watch\" + 0.007*\"movies\" + 0.006*\"don\" + 0.006*\"really\" + 0.005*\"money\"'),\n (3,\n  '0.050*\"book\" + 0.015*\"read\" + 0.005*\"author\" + 0.005*\"books\" + 0.005*\"good\" + 0.005*\"reading\" + 0.004*\"edition\" + 0.004*\"don\" + 0.003*\"better\" + 0.003*\"written\"')]"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2 - Nouns Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull out nouns from a string\n",
    "def nouns(text):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                    Text\n2      Batteries year charger Jul OK while design con...\n5      DVD Player year disc problems VCR DVD side DVD...\n6      Incorrect Disc style couple years DVD problems...\n7      DVD menu select problems DVD menu triangle key...\n9      guide format tone book author reader insider s...\n...                                                  ...\n20446  Garbage desk piece junk paint metal metal brac...\n20447  Ann job attention way detail times interest pa...\n20448  Review book stars books detail fiction books l...\n20449  Duplicate product Please product product i Hug...\n20451  buyer product amazon originals products amazon...\n\n[10000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Batteries year charger Jul OK while design con...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DVD Player year disc problems VCR DVD side DVD...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Incorrect Disc style couple years DVD problems...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DVD menu select problems DVD menu triangle key...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>guide format tone book author reader insider s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20446</th>\n      <td>Garbage desk piece junk paint metal metal brac...</td>\n    </tr>\n    <tr>\n      <th>20447</th>\n      <td>Ann job attention way detail times interest pa...</td>\n    </tr>\n    <tr>\n      <th>20448</th>\n      <td>Review book stars books detail fiction books l...</td>\n    </tr>\n    <tr>\n      <th>20449</th>\n      <td>Duplicate product Please product product i Hug...</td>\n    </tr>\n    <tr>\n      <th>20451</th>\n      <td>buyer product amazon originals products amazon...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "nouns_only = pd.DataFrame(df1['Text'].apply(nouns))\n",
    "nouns_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       000  01  010  02  04  06  08  10  100  100a  ...  zzzzzzzzzzz  \\\n2        0   0    0   0   0   0   0   0    0     0  ...            0   \n5        0   0    0   0   0   0   0   0    0     0  ...            0   \n6        0   0    0   0   0   0   0   0    0     0  ...            0   \n7        0   0    0   0   0   0   0   0    0     0  ...            0   \n9        0   0    0   0   0   0   0   0    0     0  ...            0   \n...    ...  ..  ...  ..  ..  ..  ..  ..  ...   ...  ...          ...   \n20446    0   0    0   0   0   0   0   0    0     0  ...            0   \n20447    0   0    0   0   0   0   0   0    0     0  ...            0   \n20448    0   0    0   0   0   0   0   0    0     0  ...            0   \n20449    0   0    0   0   0   0   0   0    0     0  ...            0   \n20451    0   0    0   0   0   0   0   0    0     0  ...            0   \n\n       zzzzzzzzzzzz  zzzzzzzzzzzzz  zzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzz  \\\n2                 0              0                0                 0   \n5                 0              0                0                 0   \n6                 0              0                0                 0   \n7                 0              0                0                 0   \n9                 0              0                0                 0   \n...             ...            ...              ...               ...   \n20446             0              0                0                 0   \n20447             0              0                0                 0   \n20448             0              0                0                 0   \n20449             0              0                0                 0   \n20451             0              0                0                 0   \n\n       zzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzzzzzz  ésta  \\\n2                      0                   0                       0     0   \n5                      0                   0                       0     0   \n6                      0                   0                       0     0   \n7                      0                   0                       0     0   \n9                      0                   0                       0     0   \n...                  ...                 ...                     ...   ...   \n20446                  0                   0                       0     0   \n20447                  0                   0                       0     0   \n20448                  0                   0                       0     0   \n20449                  0                   0                       0     0   \n20451                  0                   0                       0     0   \n\n       único  \n2          0  \n5          0  \n6          0  \n7          0  \n9          0  \n...      ...  \n20446      0  \n20447      0  \n20448      0  \n20449      0  \n20451      0  \n\n[10000 rows x 23857 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000</th>\n      <th>01</th>\n      <th>010</th>\n      <th>02</th>\n      <th>04</th>\n      <th>06</th>\n      <th>08</th>\n      <th>10</th>\n      <th>100</th>\n      <th>100a</th>\n      <th>...</th>\n      <th>zzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzzzzzz</th>\n      <th>ésta</th>\n      <th>único</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20446</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20447</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20448</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20449</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20451</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 23857 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "\n",
    "\n",
    "# Remove any extra stop words \n",
    "additional_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "# Count vectorizer for only nouns\n",
    "cvn = CountVectorizer(stop_words = stop_words)\n",
    "cvn_data = cvn.fit_transform(nouns_only.Text)\n",
    "dtm_nouns = pd.DataFrame(cvn_data.toarray(), columns=cvn.get_feature_names())\n",
    "dtm_nouns.index = nouns_only.index\n",
    "dtm_nouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim corpus\n",
    "corpus_n = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(dtm_nouns.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2word_n = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.050*\"book\" + 0.029*\"movie\" + 0.010*\"film\" + 0.010*\"story\" + 0.007*\"books\" + 0.006*\"characters\" + 0.006*\"plot\" + 0.005*\"way\" + 0.005*\"author\" + 0.005*\"money\"'),\n (1,\n  '0.011*\"product\" + 0.010*\"cd\" + 0.009*\"dvd\" + 0.009*\"album\" + 0.009*\"money\" + 0.008*\"music\" + 0.008*\"quality\" + 0.006*\"songs\" + 0.005*\"amazon\" + 0.004*\"way\"')]"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Starting with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpus_n, num_topics=2, id2word=id2word_n, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.074*\"book\" + 0.012*\"story\" + 0.011*\"books\" + 0.009*\"characters\" + 0.007*\"author\" + 0.006*\"way\" + 0.005*\"plot\" + 0.005*\"character\" + 0.005*\"pages\" + 0.005*\"series\"'),\n (1,\n  '0.042*\"movie\" + 0.015*\"film\" + 0.013*\"dvd\" + 0.009*\"money\" + 0.007*\"quality\" + 0.007*\"movies\" + 0.006*\"version\" + 0.005*\"product\" + 0.005*\"thing\" + 0.005*\"game\"'),\n (2,\n  '0.017*\"cd\" + 0.016*\"album\" + 0.012*\"music\" + 0.012*\"product\" + 0.010*\"songs\" + 0.007*\"money\" + 0.005*\"song\" + 0.005*\"amazon\" + 0.005*\"item\" + 0.005*\"band\"')]"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# Starting with 3 topics\n",
    "ldan = models.LdaModel(corpus=corpus_n, num_topics=3, id2word=id2word_n, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.023*\"cd\" + 0.021*\"album\" + 0.018*\"music\" + 0.013*\"songs\" + 0.007*\"song\" + 0.006*\"band\" + 0.006*\"voice\" + 0.005*\"money\" + 0.005*\"fan\" + 0.004*\"way\"'),\n (1,\n  '0.025*\"dvd\" + 0.016*\"version\" + 0.015*\"book\" + 0.011*\"quality\" + 0.009*\"edition\" + 0.008*\"movie\" + 0.008*\"amazon\" + 0.007*\"video\" + 0.006*\"money\" + 0.006*\"copy\"'),\n (2,\n  '0.021*\"product\" + 0.011*\"money\" + 0.007*\"quality\" + 0.006*\"game\" + 0.006*\"item\" + 0.006*\"months\" + 0.005*\"phone\" + 0.005*\"thing\" + 0.005*\"problem\" + 0.005*\"amazon\"'),\n (3,\n  '0.067*\"book\" + 0.040*\"movie\" + 0.015*\"story\" + 0.014*\"film\" + 0.010*\"books\" + 0.009*\"characters\" + 0.009*\"plot\" + 0.007*\"author\" + 0.006*\"way\" + 0.006*\"character\"')]"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "# Starting with 4 topics\n",
    "ldan = models.LdaModel(corpus=corpus_n, num_topics=4, id2word=id2word_n, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3 - Nouns and Adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull nouns and adjectives\n",
    "\n",
    "def nouns_adj(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                    Text\n2      Batteries year charger Jul OK while design nic...\n5      DVD Player year incorrect disc problems VCR ht...\n6      Incorrect Disc style couple years DVD problems...\n7      DVD menu select problems DVD menu triangle key...\n9      ultimate guide format tone book author reader ...\n...                                                  ...\n20446  Garbage desk piece junk silver paint metal met...\n20447  Ann gbood job attention way much detail many t...\n20448  Review book stars big books detail second fict...\n20449  Duplicate product Please product product i ori...\n20451  buyer fake product amazon originals different ...\n\n[10000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Batteries year charger Jul OK while design nic...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DVD Player year incorrect disc problems VCR ht...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Incorrect Disc style couple years DVD problems...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DVD menu select problems DVD menu triangle key...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ultimate guide format tone book author reader ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20446</th>\n      <td>Garbage desk piece junk silver paint metal met...</td>\n    </tr>\n    <tr>\n      <th>20447</th>\n      <td>Ann gbood job attention way much detail many t...</td>\n    </tr>\n    <tr>\n      <th>20448</th>\n      <td>Review book stars big books detail second fict...</td>\n    </tr>\n    <tr>\n      <th>20449</th>\n      <td>Duplicate product Please product product i ori...</td>\n    </tr>\n    <tr>\n      <th>20451</th>\n      <td>buyer fake product amazon originals different ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "nouns_and_adj = pd.DataFrame(df1['Text'].apply(nouns_adj))\n",
    "nouns_and_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       000  01  010  02  04  05  06  07  08  089555464x  ...  zzzzzzzzzzz  \\\n2        0   0    0   0   0   0   0   0   0           0  ...            0   \n5        0   0    0   0   0   0   0   0   0           0  ...            0   \n6        0   0    0   0   0   0   0   0   0           0  ...            0   \n7        0   0    0   0   0   0   0   0   0           0  ...            0   \n9        0   0    0   0   0   0   0   0   0           0  ...            0   \n...    ...  ..  ...  ..  ..  ..  ..  ..  ..         ...  ...          ...   \n20446    0   0    0   0   0   0   0   0   0           0  ...            0   \n20447    0   0    0   0   0   0   0   0   0           0  ...            0   \n20448    0   0    0   0   0   0   0   0   0           0  ...            0   \n20449    0   0    0   0   0   0   0   0   0           0  ...            0   \n20451    0   0    0   0   0   0   0   0   0           0  ...            0   \n\n       zzzzzzzzzzzz  zzzzzzzzzzzzz  zzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzz  \\\n2                 0              0                0                 0   \n5                 0              0                0                 0   \n6                 0              0                0                 0   \n7                 0              0                0                 0   \n9                 0              0                0                 0   \n...             ...            ...              ...               ...   \n20446             0              0                0                 0   \n20447             0              0                0                 0   \n20448             0              0                0                 0   \n20449             0              0                0                 0   \n20451             0              0                0                 0   \n\n       zzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzzzzzz  ésta  \\\n2                      0                   0                       0     0   \n5                      0                   0                       0     0   \n6                      0                   0                       0     0   \n7                      0                   0                       0     0   \n9                      0                   0                       0     0   \n...                  ...                 ...                     ...   ...   \n20446                  0                   0                       0     0   \n20447                  0                   0                       0     0   \n20448                  0                   0                       0     0   \n20449                  0                   0                       0     0   \n20451                  0                   0                       0     0   \n\n       único  \n2          0  \n5          0  \n6          0  \n7          0  \n9          0  \n...      ...  \n20446      0  \n20447      0  \n20448      0  \n20449      0  \n20451      0  \n\n[10000 rows x 27532 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000</th>\n      <th>01</th>\n      <th>010</th>\n      <th>02</th>\n      <th>04</th>\n      <th>05</th>\n      <th>06</th>\n      <th>07</th>\n      <th>08</th>\n      <th>089555464x</th>\n      <th>...</th>\n      <th>zzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzzzzzz</th>\n      <th>ésta</th>\n      <th>único</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20446</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20447</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20448</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20449</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20451</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 27532 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# Create the document-term matrix using only nouns and adjectives\n",
    "# This time, let's remove common words that occur too frequently with max_df\n",
    "# Ex- max_df of 0.80 means 'ignore terms that appear in more than 80% of the documents'\n",
    "\n",
    "# Remove any extra stop words \n",
    "additional_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people', 'the'\n",
    "                  'youre', 'got', 'gonna', 'time', 'good','think', 'yeah', 'this', 'it', 'and','said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv_na = CountVectorizer(max_df=.8, stop_words = stop_words) #, max_df is used for removing data values that appear too frequently, also known as \"corpus-specific stop words\". \n",
    "# For example, max_df=.8 means \"It ignores terms that appear in more than 80% of the documents\". \n",
    "data_cv_na = cv_na.fit_transform(nouns_and_adj['Text'])\n",
    "dtm_na = pd.DataFrame(data_cv_na.toarray(), columns=cv_na.get_feature_names())\n",
    "dtm_na.index = nouns_and_adj.index\n",
    "dtm_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpus_na = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(dtm_na.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2word_na = dict((v, k) for k, v in cv_na.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.025*\"movie\" + 0.009*\"film\" + 0.009*\"bad\" + 0.008*\"cd\" + 0.008*\"dvd\" + 0.008*\"album\" + 0.006*\"music\" + 0.006*\"story\" + 0.006*\"great\" + 0.005*\"money\"'),\n (1,\n  '0.039*\"book\" + 0.008*\"product\" + 0.006*\"money\" + 0.006*\"books\" + 0.004*\"great\" + 0.004*\"way\" + 0.004*\"quality\" + 0.004*\"author\" + 0.004*\"new\" + 0.004*\"amazon\"')]"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# Starting with 2 topics\n",
    "lda_na = models.LdaModel(corpus=corpus_na, num_topics=2, id2word=id2word_na, passes=10)\n",
    "lda_na.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.032*\"movie\" + 0.011*\"film\" + 0.010*\"cd\" + 0.010*\"dvd\" + 0.010*\"bad\" + 0.010*\"album\" + 0.008*\"music\" + 0.006*\"great\" + 0.006*\"songs\" + 0.006*\"money\"'),\n (1,\n  '0.014*\"product\" + 0.008*\"money\" + 0.007*\"quality\" + 0.006*\"amazon\" + 0.005*\"new\" + 0.005*\"great\" + 0.005*\"item\" + 0.004*\"problem\" + 0.004*\"months\" + 0.004*\"price\"'),\n (2,\n  '0.062*\"book\" + 0.009*\"story\" + 0.009*\"books\" + 0.007*\"characters\" + 0.006*\"author\" + 0.005*\"way\" + 0.004*\"pages\" + 0.004*\"novel\" + 0.004*\"plot\" + 0.004*\"boring\"')]"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "# Starting with 3 topics\n",
    "lda_na = models.LdaModel(corpus=corpus_na, num_topics=3, id2word=id2word_na, passes=10)\n",
    "lda_na.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  '0.016*\"product\" + 0.008*\"money\" + 0.007*\"quality\" + 0.006*\"amazon\" + 0.005*\"item\" + 0.005*\"great\" + 0.005*\"new\" + 0.005*\"months\" + 0.005*\"problem\" + 0.004*\"year\"'),\n (1,\n  '0.019*\"dvd\" + 0.018*\"cd\" + 0.016*\"album\" + 0.014*\"music\" + 0.010*\"songs\" + 0.008*\"version\" + 0.006*\"great\" + 0.006*\"bad\" + 0.006*\"money\" + 0.006*\"song\"'),\n (2,\n  '0.057*\"book\" + 0.009*\"game\" + 0.006*\"edition\" + 0.006*\"information\" + 0.006*\"books\" + 0.004*\"version\" + 0.004*\"author\" + 0.004*\"text\" + 0.004*\"pages\" + 0.004*\"better\"'),\n (3,\n  '0.032*\"book\" + 0.030*\"movie\" + 0.011*\"story\" + 0.011*\"film\" + 0.008*\"bad\" + 0.007*\"characters\" + 0.006*\"plot\" + 0.006*\"books\" + 0.005*\"boring\" + 0.005*\"great\"')]"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "# Starting with 4 topics\n",
    "lda_na = models.LdaModel(corpus=corpus_na, num_topics=4, id2word=id2word_na, passes=80)\n",
    "lda_na.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final thoughts\n",
    "There is no 'correct answer' in Topic Modeling. What works for one person may not work for someone else. This process requires a lot of experimentation and computation to get 'right'. <br> <br>\n",
    "LDA is only scratching the surface of Topic Modeling. There are many other methods such as: <br>\n",
    "* Latent Semantic Analysis (LSA)\n",
    "* Non Negative Matrix Factorization (NMF)\n",
    "* Probabilistic Latent Semantic Analysis (PSLA)\n",
    "* Correlated Topic Model (CTM)\n",
    "* Pachinko Allocation Model (PAM)\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
