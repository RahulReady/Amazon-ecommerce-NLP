{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_for_Customer_Reviews_using_LSTM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-kiD6NjKXW",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mACnNFq2B9rY",
        "colab_type": "text"
      },
      "source": [
        "## Step 0: Setting up the notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvEy1cKL5Zjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, LSTM\n",
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmvIP6Op4Y80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d26c1e8f-7259-44a7-81ee-52bea19c4408"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0TESbTHCJ2-",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6DRWGpV5kux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_train_dir = \"./drive/My Drive/09112020-nlp/features_train.csv\"\n",
        "features_val_dir = \"./drive/My Drive/09112020-nlp/features_val.csv\"\n",
        "features_test_dir = \"./drive/My Drive/09112020-nlp/features_test.csv\"\n",
        "labels_train_dir = \"./drive/My Drive/09112020-nlp/labels_train.csv\"\n",
        "labels_val_dir = \"./drive/My Drive/09112020-nlp/labels_val.csv\"\n",
        "labels_test_dir = \"./drive/My Drive/09112020-nlp/labels_test.csv\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146eOfiK5EGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_train = pd.read_csv(features_train_dir, header=None, names=['review'], encoding='utf-8')\n",
        "features_val = pd.read_csv(features_val_dir, header=None, names=['review'], encoding='utf-8')\n",
        "features_test = pd.read_csv(features_test_dir, header=None, names=['review'], encoding='utf-8')\n",
        "labels_train = pd.read_csv(labels_train_dir, header=None)\n",
        "labels_val = pd.read_csv(labels_val_dir, header=None)\n",
        "labels_test = pd.read_csv(labels_test_dir, header=None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYFw5UuT5dQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97637f39-b5b9-4502-e73d-c0f3bfadb285"
      },
      "source": [
        "assert len(features_train) == len(labels_train)\n",
        "assert len(features_val) == len(labels_val)\n",
        "assert len(features_test) == len(labels_test)\n",
        "\n",
        "print('train = {}; validation = {}; test = {}'.format(len(features_train), len(features_val), len(features_test)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train = 3200000; validation = 400000; test = 400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k_nTxz4DOmB",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yae2Ydh8C7Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Covert features to string type\n",
        "features_train['review'] = features_train['review'].astype(str)\n",
        "features_val['review'] = features_val['review'].astype(str)\n",
        "features_test['review'] = features_test['review'].astype(str)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JvlvfRt8P99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a tokenizer object\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "\n",
        "# Fit the tokenizer on train text\n",
        "tokenizer.fit_on_texts(features_train['review'].values.tolist())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D83sFvd0IXAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform words to sequence\n",
        "sequence_train = tokenizer.texts_to_sequences(features_train['review'])\n",
        "sequence_val = tokenizer.texts_to_sequences(features_val['review'])\n",
        "sequence_test = tokenizer.texts_to_sequences(features_test['review'])\n",
        "\n",
        "# Pad the sequence\n",
        "max_words = 250\n",
        "X_train = sequence.pad_sequences(sequence_train, max_words)\n",
        "X_val = sequence.pad_sequences(sequence_val, max_words)\n",
        "X_test = sequence.pad_sequences(sequence_test,  max_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9qAuXqVF2Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Covert the labels to 0 (neggative) and 1 (positive)\n",
        "y_train, y_val, y_test = labels_train - 1, labels_val - 1, labels_test - 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJh9kX_7FN6c",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Building LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UVbssQF7QZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "e831cb83-33cd-4859-bc15-dc6c372a576e"
      },
      "source": [
        "# Set embedding params\n",
        "max_features = 10000 # number of features\n",
        "maxlen = 250 # length of input sequence\n",
        "embedding_size = 32 \n",
        "\n",
        "# Specify model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 250, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhBSUNxOGBCp",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcXMRUw5Jv77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "06e0de50-296a-47ad-8b23-3cb94b948b8d"
      },
      "source": [
        "# Train with early stopping strategy\n",
        "model.fit(X_train, y_train, \n",
        "          batch_size=64, epochs=100, \n",
        "          validation_data=(X_val, y_val), \n",
        "          callbacks=[EarlyStopping(patience=1)])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 837s 17ms/step - loss: 0.1990 - accuracy: 0.9203 - val_loss: 0.2008 - val_accuracy: 0.9196\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 864s 17ms/step - loss: 0.1908 - accuracy: 0.9240 - val_loss: 0.1996 - val_accuracy: 0.9202\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 911s 18ms/step - loss: 0.1858 - accuracy: 0.9263 - val_loss: 0.1981 - val_accuracy: 0.9209\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 899s 18ms/step - loss: 0.1822 - accuracy: 0.9279 - val_loss: 0.1991 - val_accuracy: 0.9210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5c7c679a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LJkiH6jeuy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stack the train and val dataset horizontally\n",
        "X_train = np.vstack((X_train, X_val))\n",
        "y_train = np.vstack((y_train, y_val))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnzEYxEfvNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "21ccea58-53a9-4640-fa96-7f5ccb120556"
      },
      "source": [
        "# Rebuild the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 250, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpb55XcRgE0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7aee0837-69fc-4604-ee69-a1bb4d2215a4"
      },
      "source": [
        "# Train the model using train and validation data\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=4)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "56250/56250 [==============================] - 909s 16ms/step - loss: 0.2331 - accuracy: 0.9045\n",
            "Epoch 2/4\n",
            "56250/56250 [==============================] - 855s 15ms/step - loss: 0.2026 - accuracy: 0.9188\n",
            "Epoch 3/4\n",
            "56250/56250 [==============================] - 849s 15ms/step - loss: 0.1920 - accuracy: 0.9235\n",
            "Epoch 4/4\n",
            "56250/56250 [==============================] - 883s 16ms/step - loss: 0.1858 - accuracy: 0.9263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7017e75fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ielFk8AaUpL",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Evaluating models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsCAeuALd5L8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37b82293-5768-4119-dd85-dabafabd82f2"
      },
      "source": [
        "_, acc = model.evaluate(X_test, y_test, batch_size=64)\n",
        "print('Accuracy rate on test set: {}%'.format(np.round(acc * 100, 2)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6250/6250 [==============================] - 44s 7ms/step - loss: 0.1993 - accuracy: 0.9201\n",
            "Accuracy rate on test set: 92.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaC3MhEeY58p",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWdVF-LpaMtA",
        "colab_type": "text"
      },
      "source": [
        "### Recurrent Neural Network Pros:\n",
        "\n",
        "* Provides powerful performance\n",
        "* Theoretically, processes input of variable length\n",
        "* Takes into account the order of sequence\n",
        "\n",
        "### Recurrent Neural Network Cons:\n",
        "\n",
        "* Computation heavy\n",
        "* Black-box modeling"
      ]
    }
  ]
}